{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp collect_data\n",
    "# all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collecting the data\n",
    "\n",
    "> This notebook covers collecting the Reddit data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from psaw import PushshiftAPI\n",
    "from tqdm import tqdm\n",
    "import datetime as dt\n",
    "import json\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lexeme-based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def query_lexeme(lex, year):\n",
    "    api = PushshiftAPI()\n",
    "    gen = api.search_comments(\n",
    "        q = lex,\n",
    "        after = int(dt.datetime(year, 1, 1).timestamp()),\n",
    "        before = int(dt.datetime(year, 12, 31).timestamp())\n",
    "    )\n",
    "    return gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "comment(author='Jean-Naimard', author_created_utc=1163570322, author_flair_css_class=None, author_flair_text=None, author_fullname='t2_qx69', body='Western canadians have always been, are and will always be utterly clueless as to the nature of Québec.\\r\\n\\r\\nHaving toiled for centuries to suppress anything that’s french, the western rednecks have always shown their utter dedication to the most basest, vile, stupid, primitive human instincts possible.\\r\\n\\r\\nWhat the west really want is to join their moronic brethen south-of-the-border and become the 51st State, so they can have \"less\" taxes, the \"right\" to carry guns, and generally be clueless ignorant rednecks, as they always have been.\\r\\n\\r\\nThere is no \"western\" nation. It’s the same anglo-saxon soup that you will find in Ontario, the Maritimes or in the US. It’s just the seasoning that changes; some cod sprinkled here, some Screech there, some crumpets here, and some angus beef there. They’re just pissed-off that they have so meager demographic weight that they cannot influence things as much as Ontario and Québec who have the highest population in Canada.\\r\\n\\r\\nYeah, I’m a separatist frog who worships Charles de Gaulle.', controversiality=0, created_utc=1164736253, distinguished=None, gilded=0, id='csse5', link_id='t3_sprl', nest_level=3, parent_id='t1_csqwh', reply_delay=22280, retrieved_on=1473807187, score=-5, stickied=False, subreddit='reddit.com', subreddit_id='t5_6', created=1164729053.0, d_={'author': 'Jean-Naimard', 'author_created_utc': 1163570322, 'author_flair_css_class': None, 'author_flair_text': None, 'author_fullname': 't2_qx69', 'body': 'Western canadians have always been, are and will always be utterly clueless as to the nature of Québec.\\r\\n\\r\\nHaving toiled for centuries to suppress anything that’s french, the western rednecks have always shown their utter dedication to the most basest, vile, stupid, primitive human instincts possible.\\r\\n\\r\\nWhat the west really want is to join their moronic brethen south-of-the-border and become the 51st State, so they can have \"less\" taxes, the \"right\" to carry guns, and generally be clueless ignorant rednecks, as they always have been.\\r\\n\\r\\nThere is no \"western\" nation. It’s the same anglo-saxon soup that you will find in Ontario, the Maritimes or in the US. It’s just the seasoning that changes; some cod sprinkled here, some Screech there, some crumpets here, and some angus beef there. They’re just pissed-off that they have so meager demographic weight that they cannot influence things as much as Ontario and Québec who have the highest population in Canada.\\r\\n\\r\\nYeah, I’m a separatist frog who worships Charles de Gaulle.', 'controversiality': 0, 'created_utc': 1164736253, 'distinguished': None, 'gilded': 0, 'id': 'csse5', 'link_id': 't3_sprl', 'nest_level': 3, 'parent_id': 't1_csqwh', 'reply_delay': 22280, 'retrieved_on': 1473807187, 'score': -5, 'stickied': False, 'subreddit': 'reddit.com', 'subreddit_id': 't5_6', 'created': 1164729053.0})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen = query_lexeme('Anglo-Saxon', 2006)\n",
    "next(gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subreddit-based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def query_subr(subreddit, year):\n",
    "    api = PushshiftAPI()\n",
    "    gen = api.search_comments(\n",
    "        subreddit = subreddit,\n",
    "        after = int(dt.datetime(int(year), 1, 1).timestamp()),\n",
    "        before = int(dt.datetime(int(year), 12, 31).timestamp())\n",
    "    )\n",
    "    return gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "comment(author='ooouuuurrrriiiii', author_created_utc=1164155492, author_flair_css_class=None, author_flair_text=None, author_fullname='t2_rxtz', body=\"It's also in Britain, so it's an Anglo-Saxon thing it seems.\", controversiality=0, created_utc=1164383206, distinguished=None, gilded=0, id='csacq', link_id='t3_s818', nest_level=5, parent_id='t1_cs9id', reply_delay=20955, retrieved_on=1473806750, score=3, stickied=False, subreddit='reddit.com', subreddit_id='t5_6', created=1164376006.0, d_={'author': 'ooouuuurrrriiiii', 'author_created_utc': 1164155492, 'author_flair_css_class': None, 'author_flair_text': None, 'author_fullname': 't2_rxtz', 'body': \"It's also in Britain, so it's an Anglo-Saxon thing it seems.\", 'controversiality': 0, 'created_utc': 1164383206, 'distinguished': None, 'gilded': 0, 'id': 'csacq', 'link_id': 't3_s818', 'nest_level': 5, 'parent_id': 't1_cs9id', 'reply_delay': 20955, 'retrieved_on': 1473806750, 'score': 3, 'stickied': False, 'subreddit': 'reddit.com', 'subreddit_id': 't5_6', 'created': 1164376006.0})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_gen = query_subr('politics', '2007')\n",
    "next(gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def get_results(gen, limit):\n",
    "    cache = []\n",
    "    for c in tqdm(gen, total=limit):\n",
    "        cache.append(c)\n",
    "        if len(cache) >= limit:\n",
    "            break\n",
    "    return cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 99/100 [00:02<00:00, 48.33it/s]\n"
     ]
    }
   ],
   "source": [
    "results = get_results(query_gen, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(results) == 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def conv_results_to_df(results):\n",
    "    df = pd.DataFrame([thing.d_ for thing in results])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = conv_results_to_df(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert comments.shape == (100, 23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                               SUP BRO\n",
       "1     You should have given the blog dude a piece of...\n",
       "2     I DONT THINK THERE IS A STONG CLAN PRESENCE IN...\n",
       "3     The problem is that the absurd is not preventi...\n",
       "4                                             [deleted]\n",
       "                            ...                        \n",
       "95    The same person who published this story is ke...\n",
       "96    I don't think that's really true, personally. ...\n",
       "97    You also wouldn't be concerned if they were dr...\n",
       "98    There are other social news websites besides r...\n",
       "99    &gt; I wouldn't be surprised if Ron Paul takes...\n",
       "Name: body, Length: 100, dtype: object"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments['body']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write out comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def comm_subr_to_csv(comments, subreddit='NaN', limit='NaN', year='NaN'):\n",
    "    dir_out = f'data/subreddit/{subreddit}'\n",
    "    if not os.path.exists(dir_out):\n",
    "        os.makedirs(dir_out)\n",
    "    comments.to_csv(\n",
    "        f'{dir_out}/{limit}_{year}.csv',\n",
    "        index=False\n",
    "    )        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comm_subr_to_csv(comments, 'politics', 100, '2007')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disk usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| n_comments | disk_usage_mb |\n",
    "|-----------:|--------------:|\n",
    "| 10000      | 3.5           |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def get_subr_year(subreddit, year, limit):\n",
    "    query_gen = query_subr(subreddit, year)\n",
    "    results = get_results(query_gen, limit)\n",
    "    comments = conv_results_to_df(results)\n",
    "    comm_subr_to_csv(comments, subreddit, limit, year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_processing.ipynb.\n",
      "Converted 01_installation.ipynb.\n",
      "Converted 02_collect-data.ipynb.\n",
      "Converted 03_read_data.ipynb.\n",
      "Converted 04_clean_data.ipynb.\n",
      "Converted 05_usage_freq.ipynb.\n",
      "Converted 06_token_emb.ipynb.\n",
      "Converted 07_type_emb.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
