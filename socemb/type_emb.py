# AUTOGENERATED! DO NOT EDIT! File to edit: 07_type_emb.ipynb (unless otherwise specified).

__all__ = ['conv_to_lowerc', 'rm_punct', 'tokenize', 'detect_short_doc', 'clean_docs', 'Corpus', 'train_emb',
           'load_model', 'get_vec_from_model']

# Cell
import re
import numpy as np
import pandas as pd

from gensim.models import Word2Vec
from gensim.models import KeyedVectors
from scipy.spatial.distance import cosine

# Cell
def conv_to_lowerc(doc):
    return doc.lower()

# Cell
def rm_punct(doc):
    return re.sub(r'[^\w\s]+', ' ', doc)

# Cell
def tokenize(doc):
    return doc.split()

# Cell
def detect_short_doc(doc, limit=10):
    if len(doc) >= limit:
        return False
    else:
        return True

# Cell
def clean_docs(docs):
    docs_clean = docs\
        .apply(conv_to_lowerc)\
        .apply(rm_punct)\
        .apply(tokenize)\
        .where(lambda x : x.apply(detect_short_doc) == False)\
        .dropna()
    return docs_clean

# Cell
class Corpus:
    """An iterator that yields sentences (lists of str)."""
    def __init__(self, docs_clean):
        self.docs_clean = docs_clean

    def __iter__(self):
        for doc in self.docs_clean:
            yield doc

# Cell
def train_emb(corpus, MIN_COUNT=5, SIZE=300, WORKERS=8, WINDOW=3):
    model = Word2Vec(
        corpus,
        min_count=MIN_COUNT,
        size=SIZE,
        workers=WORKERS,
        window=WINDOW
    )
    return model

# Cell
def load_model(SUBREDDIT: str, YEAR: int, LIMIT: int = 100_000):
    """Load word2vec model from disk."""
    model = KeyedVectors.load(f'data/vecs/{SUBREDDIT}_{YEAR}_{LIMIT}.wv', mmap='r')
    return model

# Cell
def get_vec_from_model(lex: str, model):
    return model[lex]