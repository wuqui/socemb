{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp processing\n",
    "# all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing\n",
    "\n",
    "> This notebook contains the processing pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from socemb.collect_data import *\n",
    "from socemb.read_data import *\n",
    "from socemb.type_emb import *\n",
    "from socemb.clean_data import *\n",
    "from socemb.usage_freq import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import altair as alt\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "METHOD = 'subreddit'\n",
    "SUBREDDIT = 'conservative'\n",
    "YEARS = [year for year in range(2006, 2021)]\n",
    "LIMIT = 500_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YEAR = '2006'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CORPUS_DIR = 'data/'\n",
    "VECS_DIR = 'data/vecs/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = query_subr(SUBREDDIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1301/500000 [00:59<6:28:17, 21.41it/s]/Users/quirin/opt/miniconda3/envs/socemb/lib/python3.8/site-packages/psaw/PushshiftAPI.py:252: UserWarning: Not all PushShift shards are active. Query results may be incomplete\n",
      "  warnings.warn(shards_down_message)\n",
      " 10%|█         | 51801/500000 [38:50<9:52:13, 12.61it/s] /Users/quirin/opt/miniconda3/envs/socemb/lib/python3.8/site-packages/psaw/PushshiftAPI.py:192: UserWarning: Got non 200 code 502\n",
      "  warnings.warn(\"Got non 200 code %s\" % response.status_code)\n",
      "/Users/quirin/opt/miniconda3/envs/socemb/lib/python3.8/site-packages/psaw/PushshiftAPI.py:180: UserWarning: Unable to connect to pushshift.io. Retrying after backoff.\n",
      "  warnings.warn(\"Unable to connect to pushshift.io. Retrying after backoff.\")\n",
      "100%|█████████▉| 499999/500000 [3:27:09<00:00, 40.23it/s]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7min 29s, sys: 31 s, total: 8min\n",
      "Wall time: 3h 27min 9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "results = get_results(query, LIMIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = conv_results_to_df(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comm_subr_to_csv(comments, SUBREDDIT, LIMIT, YEAR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = get_fpath_subr_yr(SUBREDDIT, LIMIT, YEAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = read_comm_csv(fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 99999 entries, 0 to 99999\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype         \n",
      "---  ------       --------------  -----         \n",
      " 0   body         99999 non-null  string        \n",
      " 1   created_utc  99999 non-null  datetime64[ns]\n",
      " 2   id           99999 non-null  string        \n",
      " 3   subreddit    99999 non-null  string        \n",
      "dtypes: datetime64[ns](1), string(3)\n",
      "memory usage: 3.8 MB\n"
     ]
    }
   ],
   "source": [
    "comments.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train type embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### per subreddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddit = 'politics'\n",
    "limit = 100_000\n",
    "years = range(2006, 2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/subreddit/askaconservative/100000_2006.csv not found on disk\n",
      "data/subreddit/askaconservative/100000_2007.csv is empty\n",
      "data/subreddit/askaconservative/100000_2008.csv is empty\n",
      "data/subreddit/askaconservative/100000_2009.csv is empty\n",
      "data/subreddit/askaconservative/100000_2010.csv is empty\n",
      "data/subreddit/askaconservative/100000_2011.csv is empty\n",
      "2012:\t1881 docs\n",
      "2013:\t4715 docs\n",
      "2014:\t13066 docs\n",
      "2015:\t11928 docs\n",
      "2016:\t11080 docs\n",
      "2017:\t27587 docs\n",
      "2018:\t37826 docs\n",
      "2019:\t70474 docs\n",
      "2020:\t67636 docs\n",
      "data/subreddit/asklibertarians/100000_2006.csv not found on disk\n",
      "data/subreddit/asklibertarians/100000_2007.csv is empty\n",
      "data/subreddit/asklibertarians/100000_2008.csv is empty\n",
      "data/subreddit/asklibertarians/100000_2009.csv is empty\n",
      "data/subreddit/asklibertarians/100000_2010.csv is empty\n",
      "data/subreddit/asklibertarians/100000_2011.csv is empty\n",
      "data/subreddit/asklibertarians/100000_2012.csv is empty\n",
      "2013:\t482 docs\n",
      "2014:\t1257 docs\n",
      "2015:\t1851 docs\n",
      "2016:\t2741 docs\n",
      "2017:\t8392 docs\n",
      "2018:\t24504 docs\n",
      "2019:\t34298 docs\n",
      "2020:\t58181 docs\n"
     ]
    }
   ],
   "source": [
    "for subreddit in ['askaconservative', 'asklibertarians']:\n",
    "    for year in years:\n",
    "        try:\n",
    "            fpath = get_fpath_subr_yr(subreddit, 100_000, year)\n",
    "            comments = read_comm_csv(fpath)\n",
    "            docs_clean = clean_docs(comments['body'])\n",
    "            corpus = Corpus(docs_clean)\n",
    "            model = train_emb(corpus)\n",
    "            wv = model.wv\n",
    "            wv.save(f'{VECS_DIR}{subreddit}_{year}_{limit}.wv')\n",
    "            print(f'{year}:\\t{len(docs_clean)} docs')\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### per year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YEAR = 2020\n",
    "LIMIT = 100_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpaths = get_fpaths_yr(YEAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Path('data/subreddit/asklibertarians/100000_2020.csv'),\n",
       " Path('data/subreddit/askaconservative/100000_2020.csv'),\n",
       " Path('data/subreddit/politics/100_2020.csv'),\n",
       " Path('data/subreddit/politics/1000_2020.csv'),\n",
       " Path('data/subreddit/politics/10000_2020.csv'),\n",
       " Path('data/subreddit/politics/100000_2020.csv'),\n",
       " Path('data/subreddit/askreddit/100000_2020.csv')]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = read_comm_csvs(fpaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_clean = clean_docs(comments['body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         [you, re, asking, how, they, re, going, to, be...\n",
       "1         [gt, i, don, t, think, there, are, any, varyin...\n",
       "2         [its, split, on, copyright, it, leans, anti, n...\n",
       "3         [that, would, be, up, to, the, land, owners, a...\n",
       "4         [i, have, him, here, gun, to, his, head, round...\n",
       "                                ...                        \n",
       "380954    [the, nature, police, are, supposed, to, be, p...\n",
       "380957    [i, got, reddit, last, year, and, only, starte...\n",
       "380958    [i, m, just, curious, how, this, is, clear, to...\n",
       "380962    [staying, at, said, job, while, being, underpa...\n",
       "380963    [i, m, not, sure, that, this, has, ever, been,...\n",
       "Name: body, Length: 264796, dtype: object"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 33s, sys: 841 ms, total: 2min 34s\n",
      "Wall time: 41.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "corpus = Corpus(docs_clean)\n",
    "model = train_emb(corpus)\n",
    "wv = model.wv\n",
    "wv.save(f'{VECS_DIR}year/{YEAR}.wv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measure semantic distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMMS = ['askaconservative', 'politics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comm = 'askaconservative'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YEARS = range(2013, 2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEX = 'trump'"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for comm in COMMS:\n",
    "    for year in YEARS:\n",
    "        model = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove bot subreddits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = rm_bots_subreddits(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove duplicate comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = rm_dupl_comments(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove comments without target tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = rm_comm_no_toks(df, LEX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate usage frequency in monthly bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m = get_monthly_freq(df)\n",
    "df_m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot usage frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_use_freq(df_m, LEX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
