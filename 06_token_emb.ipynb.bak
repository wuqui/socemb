{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "hybrid-reflection",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp token_emb\n",
    "# all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "macro-donna",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "emotional-portfolio",
   "metadata": {
    "heading_collapsed": "true",
    "tags": []
   },
   "source": [
    "# Token embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sharing-shareware",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "killing-northwest",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from flair.data import Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "falling-essence",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from flair.embeddings import WordEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "assured-rebound",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.embeddings import TransformerWordEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "seven-organization",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import CosineSimilarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "separate-phoenix",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "insured-vegetation",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = TransformerWordEmbeddings('roberta-base')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valid-tennis",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "middle-foundation",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Class-less version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optical-netscape",
   "metadata": {},
   "outputs": [],
   "source": [
    "LEX = 'bank'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saving-china",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents_strings = [\n",
    "    'He found money at the bank.', \n",
    "    'She works at a bank.', \n",
    "    \"The boat reached the river's bank.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "approved-oliver",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def proc_sentence(sent_string):\n",
    "    sent = Sentence(sent_string)\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silver-sucking",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_string = \"I can't do this.\"\n",
    "sent = proc_sentence(sent_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hazardous-riverside",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(sent) == 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amino-international",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for tok in sent:\n",
    "    print(tok, tok.embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colored-serbia",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_sentence(sent, MODEL):\n",
    "    MODEL.embed(sent)\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interracial-beach",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_emb = embed_sentence(sent, MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supported-third",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for tok in sent_emb:\n",
    "    print(tok, tok.embedding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arctic-munich",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(sent_emb) == 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "british-collective",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert sent_emb[0].embedding.shape[0] == 768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sixth-affiliate",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sent_toks(sent, lex):\n",
    "    sent_toks = []\n",
    "    for tok in sent:\n",
    "        if tok.text == lex:\n",
    "            sent_toks.append(tok)\n",
    "    return sent_toks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "general-modern",
   "metadata": {},
   "outputs": [],
   "source": [
    "lex = 'cell'\n",
    "sent = proc_sentence('A cell is a cell.')\n",
    "sent_emb = embed_sentence(sent, MODEL)\n",
    "sent_toks = get_sent_toks(sent_emb, lex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weekly-collective",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(sent_toks) == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appointed-brave",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sent_vec(sent_toks, lex):\n",
    "    sent_toks_vecs = [tok.embedding for tok in sent_toks]\n",
    "    # return vector only for the first token in the sentence, ignore the rest; alternative: take mean of all target tokens\n",
    "    sent_vec = sent_toks_vecs[0]\n",
    "    return sent_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "false-conservative",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert get_sent_vec(sent_toks, lex).shape[0] == 768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comic-tutorial",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cos_sim(vec_1, vec_2):\n",
    "    cos_sim = CosineSimilarity(dim=0)\n",
    "    sim_vecs = cos_sim(vec_1, vec_2)\n",
    "    return float(sim_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expected-vampire",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sent_sim(sent_1, sent_2, lex):\n",
    "    sent_vec_1 = get_sent_vec_\n",
    "    cos_sim = get_cos_sim(sent_vec_1, sent_vec_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "banned-barbados",
   "metadata": {},
   "source": [
    "### Class version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regulated-helmet",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "changed-oklahoma",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastcore.basics import patch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modified-admission",
   "metadata": {},
   "source": [
    "#### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "perceived-virus",
   "metadata": {},
   "outputs": [],
   "source": [
    "lex = 'bank'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "acknowledged-elevation",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents_strings = [\n",
    "    'He found money at the bank.', \n",
    "    'She works at a bank.', \n",
    "    \"The boat reached the river's bank.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "pending-garbage",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_string = sents_strings[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "welcome-dover",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Initialize `Sent` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "polish-canon",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sent():\n",
    "    def __init__(self, string, model):\n",
    "        self.string = string\n",
    "        self.model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "congressional-circular",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = Sent(sent_string, MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "flying-jordan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'He found money at the bank.'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent.string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cheap-infection",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Tokenize sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "special-pavilion",
   "metadata": {},
   "outputs": [],
   "source": [
    "@patch(as_prop=True)\n",
    "def sent(self: Sent):\n",
    "    return Sentence(self.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "noted-indian",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: 1 He\n",
      "Token: 2 found\n",
      "Token: 3 money\n",
      "Token: 4 at\n",
      "Token: 5 the\n",
      "Token: 6 bank\n",
      "Token: 7 .\n"
     ]
    }
   ],
   "source": [
    "for tok in sent.sent:\n",
    "    print(tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "unlimited-waste",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(sent.sent) == 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tribal-small",
   "metadata": {},
   "source": [
    "#### Embed sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "different-magazine",
   "metadata": {},
   "outputs": [],
   "source": [
    "@patch\n",
    "def get_sent_emb(self: Sent):\n",
    "    sent_tmp = self.sent\n",
    "    self.model.embed(sent_tmp)\n",
    "    return sent_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "complimentary-entertainment",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = Sent(sent_string, MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "reasonable-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_emb = sent.get_sent_emb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "committed-morgan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: 1 He torch.Size([768])\n",
      "Token: 2 found torch.Size([768])\n",
      "Token: 3 money torch.Size([768])\n",
      "Token: 4 at torch.Size([768])\n",
      "Token: 5 the torch.Size([768])\n",
      "Token: 6 bank torch.Size([768])\n",
      "Token: 7 . torch.Size([768])\n"
     ]
    }
   ],
   "source": [
    "for tok in sent_emb:\n",
    "    print(tok, tok.embedding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "sought-onion",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(sent_emb) == 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "separated-dominant",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert sent_emb[0].embedding.shape[0] == 768"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "competent-backup",
   "metadata": {},
   "source": [
    "#### Get target tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "expected-suggestion",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_toks_tgt(sent, lex):\n",
    "    sent_toks = []\n",
    "    for tok in sent:\n",
    "        if tok.text == lex:\n",
    "            sent_toks.append(tok)\n",
    "    return sent_toks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "running-professor",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_toks_tgt = get_toks_tgt(sent.sent, lex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ruled-repair",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(sent_toks_tgt) == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "false-highway",
   "metadata": {},
   "source": [
    "#### Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "hearing-ability",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Token: 6 bank]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_toks_tgt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "reflected-money",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'He found money at the bank.'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent.string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "sophisticated-interim",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tok:\n",
    "    def __init__(self, Token, Sent):\n",
    "        self.text = Token.text\n",
    "        self.context = Sent.string\n",
    "        self.embedding = Token.embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "brutal-costume",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Sentence' object has no attribute 'sent'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-120-1666a73d8c76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mtok\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msent_emb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mtok\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTok\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtok\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtok\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtok\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtok\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Sentence' object has no attribute 'sent'"
     ]
    }
   ],
   "source": [
    "for tok in sent_emb.sent:\n",
    "    tok = Tok(tok, sent)\n",
    "    print(tok.text, tok.context, tok.embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "interim-breast",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: 6 bank tensor([])\n"
     ]
    }
   ],
   "source": [
    "for tok in toks:\n",
    "    print(tok, tok.embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "integrated-corner",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sent_vec(sent_toks, lex):\n",
    "    sent_toks_vecs = [tok.embedding for tok in sent_toks]\n",
    "    # return vector only for the first token in the sentence, ignore the rest; alternative: take mean of all target tokens\n",
    "    sent_vec = sent_toks_vecs[0]\n",
    "    return sent_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fantastic-announcement",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sent_toks' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-429d343265a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mget_sent_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent_toks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m768\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'sent_toks' is not defined"
     ]
    }
   ],
   "source": [
    "assert get_sent_vec(sent_toks, lex).shape[0] == 768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foreign-madagascar",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cos_sim(vec_1, vec_2):\n",
    "    cos_sim = CosineSimilarity(dim=0)\n",
    "    sim_vecs = cos_sim(vec_1, vec_2)\n",
    "    return float(sim_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anticipated-timothy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sent_sim(sent_1, sent_2, lex):\n",
    "    sent_vec_1 = get_sent_vec_\n",
    "    cos_sim = get_cos_sim(sent_vec_1, sent_vec_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "utility-wagner",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Type-based embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "damaged-secret",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embedding = WordEmbeddings('glove')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pursuant-thousand",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = Sentence('I can can a can.')\n",
    "embedding.embed(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arranged-queen",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for token in sentence:\n",
    "    print(token)\n",
    "    print(token.embedding.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atmospheric-mention",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Token-based embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "passing-living",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Toy example: 'bank'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "current-forty",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = [proc_sentence(sent) for sent in sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "guilty-twelve",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_vecs = [get_sent_vec(sent, lex) for sent in sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entitled-conviction",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_vecs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "theoretical-patch",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sent_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tough-sheffield",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_cos_sim(sent_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breeding-amber",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\n",
    "    cos(vecs[0], vecs[1]),\n",
    "    cos(vecs[0], vecs[2]),\n",
    "    cos(vecs[1], vecs[2]),    \n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adequate-delight",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert cos(vecs[0], vecs[1]) > cos(vecs[0], vecs[2])\n",
    "assert cos(vecs[0], vecs[1]) > cos(vecs[1], vecs[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smooth-mumbai",
   "metadata": {},
   "source": [
    "### 'Cell'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "removed-toyota",
   "metadata": {},
   "outputs": [],
   "source": [
    "lex = 'cell'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "described-inflation",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = [\n",
    "    'I bought a new cell phone yesterday.',\n",
    "    'Stem cell research has found a cure for cancer.'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ultimate-laser",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = [Sentence(comm) for comm in comments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aware-ferry",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents_embed = embedding.embed([sent for sent in sents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fourth-indonesia",
   "metadata": {},
   "outputs": [],
   "source": [
    "vecs = [tok.embedding for tok in toks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thermal-compression",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tok in Sentence(comments[0]):\n",
    "    if tok.text == 'cell':\n",
    "        print(tok, tok.embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metropolitan-celebrity",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 'Anglo-Saxon' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prompt-softball",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from flair.data import Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "substantial-massachusetts",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.embeddings import TransformerWordEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "underlying-parks",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entire-landscape",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = df.body[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sought-incident",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = \"This is a sentence. This is another sentence. I love Berlin.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "described-substance",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = SegtokSentenceSplitter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certified-simon",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = splitter.split(txt)\n",
    "\n",
    "print(len(sents), '\\n')\n",
    "\n",
    "for sent in sents:\n",
    "    print(len(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exterior-closure",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.choices(sents, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "basic-heater",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.choices(df['body'], k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worth-teens",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = [\n",
    "    'At the same time, as the Anglo Saxons began settling in Roman territory, they began adopting vulgar Latin words into their vocabulary.',\n",
    "    'Islamophobia here tends to refer to the racism from the WASP (white Anglo-Saxon Protestant)-types.'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beneficial-chamber",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "rep = {\"anglo saxon\": \"anglo-saxon\", \"anglo-saxons\": \"anglo-saxon\"} \n",
    "rep = dict((re.escape(k), v) for k, v in rep.items())\n",
    "pattern = re.compile(\"|\".join(rep.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "centered-optimum",
   "metadata": {},
   "outputs": [],
   "source": [
    "[pattern.sub(lambda m: rep[re.escape(m.group(0))], comment) for comment in comments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interstate-rescue",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_sents = [splitter.split(comment) for comment in comments]\n",
    "\n",
    "print(len(comments_sents), '\\n')\n",
    "\n",
    "for comment in comments_sents:\n",
    "    print(len(comment))\n",
    "    for sent in comment:\n",
    "        print(sent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "royal-hostel",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent.replace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "treated-orange",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_low = [comm.lower() for comm in comments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unauthorized-place",
   "metadata": {},
   "outputs": [],
   "source": [
    "lex = 'Anglo-Saxon'\n",
    "patterns = ['Anglo-Saxon', 'Anglo Sa']\n",
    "\n",
    "comments_tokmerge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ranking-yemen",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = [Sentence(txt) for txt in txts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recent-uncle",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents_toks = []\n",
    "for sent in sents:\n",
    "    toks = 0\n",
    "    for tok in sent:\n",
    "        if tok.text == 'Anglo-Saxon':\n",
    "            toks += 1\n",
    "    if toks >= 1:\n",
    "        print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consolidated-superintendent",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.choices(sents, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sudden-classics",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = 'Anglo-Saxon Anglo Saxon people'\n",
    "sent = Sentence(sent)\n",
    "\n",
    "for tok in sent:\n",
    "    if tok.text == 'Anglo-Saxon':\n",
    "        print(tok)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
