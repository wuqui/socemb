{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complete-mailman",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp token_emb\n",
    "# all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recreational-knock",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "objective-think",
   "metadata": {},
   "source": [
    "# Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "radical-graduation",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sublime-royal",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.data import Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "speaking-database",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.embeddings import WordEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greenhouse-medline",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.embeddings import TransformerWordEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rational-argument",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import CosineSimilarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "planned-station",
   "metadata": {},
   "source": [
    "### Load language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confirmed-banana",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = TransformerWordEmbeddings('roberta-base')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oriental-crawford",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "peaceful-vegetation",
   "metadata": {},
   "source": [
    "### Class-less version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "combined-individual",
   "metadata": {},
   "outputs": [],
   "source": [
    "LEX = 'bank'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "joint-cornwall",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents_strings = [\n",
    "    'He found money at the bank.', \n",
    "    'She works at a bank.', \n",
    "    \"The boat reached the river's bank.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solved-affairs",
   "metadata": {},
   "outputs": [],
   "source": [
    "def proc_sentence(sent_string):\n",
    "    sent = Sentence(sent_string)\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alternate-muslim",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_string = \"I can't do this.\"\n",
    "sent = proc_sentence(sent_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civilian-diesel",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(sent) == 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generic-modem",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tok in sent:\n",
    "    print(tok, tok.embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liberal-cycle",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_sentence(sent, MODEL):\n",
    "    MODEL.embed(sent)\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affiliated-wholesale",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_emb = embed_sentence(sent, MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acute-tuning",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tok in sent_emb:\n",
    "    print(tok, tok.embedding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "honey-clearing",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(sent_emb) == 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alien-agenda",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert sent_emb[0].embedding.shape[0] == 768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "processed-showcase",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sent_toks(sent, lex):\n",
    "    sent_toks = []\n",
    "    for tok in sent:\n",
    "        if tok.text == lex:\n",
    "            sent_toks.append(tok)\n",
    "    return sent_toks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "available-payday",
   "metadata": {},
   "outputs": [],
   "source": [
    "lex = 'cell'\n",
    "sent = proc_sentence('A cell is a cell.')\n",
    "sent_emb = embed_sentence(sent, MODEL)\n",
    "sent_toks = get_sent_toks(sent_emb, lex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "understanding-coordination",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(sent_toks) == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "universal-cement",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sent_vec(sent_toks, lex):\n",
    "    sent_toks_vecs = [tok.embedding for tok in sent_toks]\n",
    "    # return vector only for the first token in the sentence, ignore the rest; alternative: take mean of all target tokens\n",
    "    sent_vec = sent_toks_vecs[0]\n",
    "    return sent_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subject-dating",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert get_sent_vec(sent_toks, lex).shape[0] == 768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "artificial-version",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cos_sim(vec_1, vec_2):\n",
    "    cos_sim = CosineSimilarity(dim=0)\n",
    "    sim_vecs = cos_sim(vec_1, vec_2)\n",
    "    return float(sim_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satisfied-paste",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sent_sim(sent_1, sent_2, lex):\n",
    "    sent_vec_1 = get_sent_vec_\n",
    "    cos_sim = get_cos_sim(sent_vec_1, sent_vec_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "restricted-daniel",
   "metadata": {},
   "source": [
    "### Class version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "green-parts",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excess-burlington",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastcore.basics import patch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accessible-minnesota",
   "metadata": {},
   "source": [
    "#### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becoming-webcam",
   "metadata": {},
   "outputs": [],
   "source": [
    "lex = 'bank'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stuck-herald",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents_strings = [\n",
    "    'He found money at the bank.', \n",
    "    'She works at a bank.', \n",
    "    \"The boat reached the river's bank.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confirmed-museum",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_string = sents_strings[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "danish-jewelry",
   "metadata": {},
   "source": [
    "#### Initialize `Sent` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quiet-neighborhood",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sent():\n",
    "    def __init__(self, string, model):\n",
    "        self.string = string\n",
    "        self.model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "christian-delhi",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = Sent(sent_string, MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "israeli-vacation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'He found money at the bank.'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent.string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virgin-beaver",
   "metadata": {},
   "source": [
    "#### Tokenize sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "characteristic-composer",
   "metadata": {},
   "outputs": [],
   "source": [
    "@patch(as_prop=True)\n",
    "def sent(self: Sent):\n",
    "    return Sentence(self.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exciting-collect",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: 1 He\n",
      "Token: 2 found\n",
      "Token: 3 money\n",
      "Token: 4 at\n",
      "Token: 5 the\n",
      "Token: 6 bank\n",
      "Token: 7 .\n"
     ]
    }
   ],
   "source": [
    "for tok in sent.sent:\n",
    "    print(tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "painted-encounter",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(sent.sent) == 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amber-department",
   "metadata": {},
   "source": [
    "#### Embed sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minimal-slide",
   "metadata": {},
   "outputs": [],
   "source": [
    "@patch\n",
    "def get_sent_emb(self: Sent):\n",
    "    sent_tmp = self.sent\n",
    "    self.model.embed(sent_tmp)\n",
    "    return sent_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "israeli-roman",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = Sent(sent_string, MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cellular-memory",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_emb = sent.get_sent_emb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "filled-majority",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: 1 He torch.Size([768])\n",
      "Token: 2 found torch.Size([768])\n",
      "Token: 3 money torch.Size([768])\n",
      "Token: 4 at torch.Size([768])\n",
      "Token: 5 the torch.Size([768])\n",
      "Token: 6 bank torch.Size([768])\n",
      "Token: 7 . torch.Size([768])\n"
     ]
    }
   ],
   "source": [
    "for tok in sent_emb:\n",
    "    print(tok, tok.embedding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "realistic-sixth",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(sent_emb) == 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extreme-intellectual",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert sent_emb[0].embedding.shape[0] == 768"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "musical-antenna",
   "metadata": {},
   "source": [
    "#### Get target tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pointed-objective",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_toks_tgt(sent, lex):\n",
    "    sent_toks = []\n",
    "    for tok in sent:\n",
    "        if tok.text == lex:\n",
    "            sent_toks.append(tok)\n",
    "    return sent_toks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deluxe-settlement",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_toks_tgt = get_toks_tgt(sent.sent, lex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affiliated-conviction",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(sent_toks_tgt) == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dental-breed",
   "metadata": {},
   "source": [
    "#### Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "promising-collins",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Token: 6 bank]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_toks_tgt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scheduled-silver",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'He found money at the bank.'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent.string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amazing-belle",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tok:\n",
    "    def __init__(self, Token, Sent):\n",
    "        self.text = Token.text\n",
    "        self.context = Sent.string\n",
    "        self.embedding = Token.embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instrumental-aquatic",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Sentence' object has no attribute 'sent'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-120-1666a73d8c76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mtok\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msent_emb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mtok\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTok\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtok\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtok\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtok\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtok\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Sentence' object has no attribute 'sent'"
     ]
    }
   ],
   "source": [
    "for tok in sent_emb.sent:\n",
    "    tok = Tok(tok, sent)\n",
    "    print(tok.text, tok.context, tok.embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "religious-attempt",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: 6 bank tensor([])\n"
     ]
    }
   ],
   "source": [
    "for tok in toks:\n",
    "    print(tok, tok.embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "union-homeless",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sent_vec(sent_toks, lex):\n",
    "    sent_toks_vecs = [tok.embedding for tok in sent_toks]\n",
    "    # return vector only for the first token in the sentence, ignore the rest; alternative: take mean of all target tokens\n",
    "    sent_vec = sent_toks_vecs[0]\n",
    "    return sent_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funded-aurora",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sent_toks' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-429d343265a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mget_sent_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent_toks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m768\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'sent_toks' is not defined"
     ]
    }
   ],
   "source": [
    "assert get_sent_vec(sent_toks, lex).shape[0] == 768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fuzzy-launch",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cos_sim(vec_1, vec_2):\n",
    "    cos_sim = CosineSimilarity(dim=0)\n",
    "    sim_vecs = cos_sim(vec_1, vec_2)\n",
    "    return float(sim_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chemical-oxford",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sent_sim(sent_1, sent_2, lex):\n",
    "    sent_vec_1 = get_sent_vec_\n",
    "    cos_sim = get_cos_sim(sent_vec_1, sent_vec_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modular-mechanism",
   "metadata": {},
   "source": [
    "## Type-based embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optimum-crack",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = WordEmbeddings('glove')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secondary-answer",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = Sentence('I can can a can.')\n",
    "embedding.embed(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medical-conference",
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in sentence:\n",
    "    print(token)\n",
    "    print(token.embedding.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interracial-ecuador",
   "metadata": {},
   "source": [
    "## Token-based embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tropical-visit",
   "metadata": {},
   "source": [
    "### Toy example: 'bank'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proved-summit",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = [proc_sentence(sent) for sent in sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amateur-shell",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_vecs = [get_sent_vec(sent, lex) for sent in sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "editorial-superior",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_vecs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "commercial-judges",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sent_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efficient-review",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_cos_sim(sent_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "round-module",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    cos(vecs[0], vecs[1]),\n",
    "    cos(vecs[0], vecs[2]),\n",
    "    cos(vecs[1], vecs[2]),    \n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "earlier-asthma",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert cos(vecs[0], vecs[1]) > cos(vecs[0], vecs[2])\n",
    "assert cos(vecs[0], vecs[1]) > cos(vecs[1], vecs[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hawaiian-protection",
   "metadata": {},
   "source": [
    "### 'Cell'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electric-conjunction",
   "metadata": {},
   "outputs": [],
   "source": [
    "lex = 'cell'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reliable-space",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = [\n",
    "    'I bought a new cell phone yesterday.',\n",
    "    'Stem cell research has found a cure for cancer.'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "italian-skating",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = [Sentence(comm) for comm in comments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "massive-titanium",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents_embed = embedding.embed([sent for sent in sents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "casual-welcome",
   "metadata": {},
   "outputs": [],
   "source": [
    "vecs = [tok.embedding for tok in toks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "authentic-jacksonville",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tok in Sentence(comments[0]):\n",
    "    if tok.text == 'cell':\n",
    "        print(tok, tok.embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sonic-updating",
   "metadata": {},
   "source": [
    "### 'Anglo-Saxon' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optical-footwear",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.data import Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "center-monroe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.embeddings import TransformerWordEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mathematical-syracuse",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "persistent-lounge",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = df.body[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specific-romance",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = \"This is a sentence. This is another sentence. I love Berlin.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proved-ethnic",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = SegtokSentenceSplitter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prime-texas",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = splitter.split(txt)\n",
    "\n",
    "print(len(sents), '\\n')\n",
    "\n",
    "for sent in sents:\n",
    "    print(len(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "geographic-aspect",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.choices(sents, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broke-adjustment",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.choices(df['body'], k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worst-rwanda",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = [\n",
    "    'At the same time, as the Anglo Saxons began settling in Roman territory, they began adopting vulgar Latin words into their vocabulary.',\n",
    "    'Islamophobia here tends to refer to the racism from the WASP (white Anglo-Saxon Protestant)-types.'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "treated-event",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "rep = {\"anglo saxon\": \"anglo-saxon\", \"anglo-saxons\": \"anglo-saxon\"} \n",
    "rep = dict((re.escape(k), v) for k, v in rep.items())\n",
    "pattern = re.compile(\"|\".join(rep.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deluxe-correction",
   "metadata": {},
   "outputs": [],
   "source": [
    "[pattern.sub(lambda m: rep[re.escape(m.group(0))], comment) for comment in comments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instrumental-residence",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_sents = [splitter.split(comment) for comment in comments]\n",
    "\n",
    "print(len(comments_sents), '\\n')\n",
    "\n",
    "for comment in comments_sents:\n",
    "    print(len(comment))\n",
    "    for sent in comment:\n",
    "        print(sent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chinese-poison",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent.replace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anonymous-breath",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_low = [comm.lower() for comm in comments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "norwegian-horse",
   "metadata": {},
   "outputs": [],
   "source": [
    "lex = 'Anglo-Saxon'\n",
    "patterns = ['Anglo-Saxon', 'Anglo Sa']\n",
    "\n",
    "comments_tokmerge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "referenced-simple",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = [Sentence(txt) for txt in txts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mental-training",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents_toks = []\n",
    "for sent in sents:\n",
    "    toks = 0\n",
    "    for tok in sent:\n",
    "        if tok.text == 'Anglo-Saxon':\n",
    "            toks += 1\n",
    "    if toks >= 1:\n",
    "        print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "external-chaos",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.choices(sents, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tired-signal",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = 'Anglo-Saxon Anglo Saxon people'\n",
    "sent = Sentence(sent)\n",
    "\n",
    "for tok in sent:\n",
    "    if tok.text == 'Anglo-Saxon':\n",
    "        print(tok)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
