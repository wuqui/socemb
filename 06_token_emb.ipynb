{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjustable-bermuda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp token_emb\n",
    "# all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "private-hospital",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "threaded-voluntary",
   "metadata": {},
   "source": [
    "# Token embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "balanced-anthropology",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "static-treat",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.data import Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "female-springfield",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.embeddings import WordEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numeric-yahoo",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.embeddings import TransformerWordEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interstate-packaging",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import CosineSimilarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "educated-reminder",
   "metadata": {},
   "source": [
    "### Load language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alternative-genealogy",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = TransformerWordEmbeddings('roberta-base')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "centered-anchor",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wooden-malpractice",
   "metadata": {},
   "source": [
    "### Class-less version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enhanced-metabolism",
   "metadata": {},
   "outputs": [],
   "source": [
    "LEX = 'bank'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stock-reunion",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents_strings = [\n",
    "    'He found money at the bank.', \n",
    "    'She works at a bank.', \n",
    "    \"The boat reached the river's bank.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "curious-contest",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def proc_sentence(sent_string):\n",
    "    sent = Sentence(sent_string)\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corresponding-chain",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_string = \"I can't do this.\"\n",
    "sent = proc_sentence(sent_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seven-glory",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(sent) == 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dental-narrative",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tok in sent:\n",
    "    print(tok, tok.embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exciting-consent",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_sentence(sent, MODEL):\n",
    "    MODEL.embed(sent)\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bearing-commerce",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_emb = embed_sentence(sent, MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strategic-vatican",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tok in sent_emb:\n",
    "    print(tok, tok.embedding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjacent-wesley",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(sent_emb) == 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "built-comedy",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert sent_emb[0].embedding.shape[0] == 768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hybrid-wilson",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sent_toks(sent, lex):\n",
    "    sent_toks = []\n",
    "    for tok in sent:\n",
    "        if tok.text == lex:\n",
    "            sent_toks.append(tok)\n",
    "    return sent_toks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "derived-questionnaire",
   "metadata": {},
   "outputs": [],
   "source": [
    "lex = 'cell'\n",
    "sent = proc_sentence('A cell is a cell.')\n",
    "sent_emb = embed_sentence(sent, MODEL)\n",
    "sent_toks = get_sent_toks(sent_emb, lex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tired-vector",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(sent_toks) == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forced-usage",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sent_vec(sent_toks, lex):\n",
    "    sent_toks_vecs = [tok.embedding for tok in sent_toks]\n",
    "    # return vector only for the first token in the sentence, ignore the rest; alternative: take mean of all target tokens\n",
    "    sent_vec = sent_toks_vecs[0]\n",
    "    return sent_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "patent-policy",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert get_sent_vec(sent_toks, lex).shape[0] == 768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statewide-findings",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cos_sim(vec_1, vec_2):\n",
    "    cos_sim = CosineSimilarity(dim=0)\n",
    "    sim_vecs = cos_sim(vec_1, vec_2)\n",
    "    return float(sim_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grave-repair",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sent_sim(sent_1, sent_2, lex):\n",
    "    sent_vec_1 = get_sent_vec_\n",
    "    cos_sim = get_cos_sim(sent_vec_1, sent_vec_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "careful-conjunction",
   "metadata": {},
   "source": [
    "### Class version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eastern-foster",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extreme-casino",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastcore.basics import patch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hollywood-tamil",
   "metadata": {},
   "source": [
    "#### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "maritime-display",
   "metadata": {},
   "outputs": [],
   "source": [
    "lex = 'bank'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detailed-freedom",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents_strings = [\n",
    "    'He found money at the bank.', \n",
    "    'She works at a bank.', \n",
    "    \"The boat reached the river's bank.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprising-catalyst",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_string = sents_strings[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numerical-recommendation",
   "metadata": {},
   "source": [
    "#### Initialize `Sent` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "trained-examination",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sent():\n",
    "    def __init__(self, string, model):\n",
    "        self.string = string\n",
    "        self.model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indonesian-olympus",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = Sent(sent_string, MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specialized-stone",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'He found money at the bank.'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent.string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exclusive-dinner",
   "metadata": {},
   "source": [
    "#### Tokenize sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pediatric-explanation",
   "metadata": {},
   "outputs": [],
   "source": [
    "@patch(as_prop=True)\n",
    "def sent(self: Sent):\n",
    "    return Sentence(self.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "economic-membership",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: 1 He\n",
      "Token: 2 found\n",
      "Token: 3 money\n",
      "Token: 4 at\n",
      "Token: 5 the\n",
      "Token: 6 bank\n",
      "Token: 7 .\n"
     ]
    }
   ],
   "source": [
    "for tok in sent.sent:\n",
    "    print(tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competitive-organic",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(sent.sent) == 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subsequent-angel",
   "metadata": {},
   "source": [
    "#### Embed sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tracked-emission",
   "metadata": {},
   "outputs": [],
   "source": [
    "@patch\n",
    "def get_sent_emb(self: Sent):\n",
    "    sent_tmp = self.sent\n",
    "    self.model.embed(sent_tmp)\n",
    "    return sent_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attractive-consent",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = Sent(sent_string, MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foster-campbell",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_emb = sent.get_sent_emb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "turkish-employment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: 1 He torch.Size([768])\n",
      "Token: 2 found torch.Size([768])\n",
      "Token: 3 money torch.Size([768])\n",
      "Token: 4 at torch.Size([768])\n",
      "Token: 5 the torch.Size([768])\n",
      "Token: 6 bank torch.Size([768])\n",
      "Token: 7 . torch.Size([768])\n"
     ]
    }
   ],
   "source": [
    "for tok in sent_emb:\n",
    "    print(tok, tok.embedding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opened-depression",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(sent_emb) == 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cubic-transfer",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert sent_emb[0].embedding.shape[0] == 768"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dressed-chinese",
   "metadata": {},
   "source": [
    "#### Get target tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "touched-screening",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_toks_tgt(sent, lex):\n",
    "    sent_toks = []\n",
    "    for tok in sent:\n",
    "        if tok.text == lex:\n",
    "            sent_toks.append(tok)\n",
    "    return sent_toks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hispanic-blair",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_toks_tgt = get_toks_tgt(sent.sent, lex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "horizontal-account",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(sent_toks_tgt) == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baking-details",
   "metadata": {},
   "source": [
    "#### Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spare-bermuda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Token: 6 bank]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_toks_tgt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "established-broadcast",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'He found money at the bank.'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent.string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mobile-indonesia",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tok:\n",
    "    def __init__(self, Token, Sent):\n",
    "        self.text = Token.text\n",
    "        self.context = Sent.string\n",
    "        self.embedding = Token.embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hired-leone",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Sentence' object has no attribute 'sent'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-120-1666a73d8c76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mtok\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msent_emb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mtok\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTok\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtok\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtok\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtok\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtok\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Sentence' object has no attribute 'sent'"
     ]
    }
   ],
   "source": [
    "for tok in sent_emb.sent:\n",
    "    tok = Tok(tok, sent)\n",
    "    print(tok.text, tok.context, tok.embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "auburn-catalog",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: 6 bank tensor([])\n"
     ]
    }
   ],
   "source": [
    "for tok in toks:\n",
    "    print(tok, tok.embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "referenced-franchise",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sent_vec(sent_toks, lex):\n",
    "    sent_toks_vecs = [tok.embedding for tok in sent_toks]\n",
    "    # return vector only for the first token in the sentence, ignore the rest; alternative: take mean of all target tokens\n",
    "    sent_vec = sent_toks_vecs[0]\n",
    "    return sent_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "integrated-affair",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sent_toks' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-429d343265a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mget_sent_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent_toks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m768\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'sent_toks' is not defined"
     ]
    }
   ],
   "source": [
    "assert get_sent_vec(sent_toks, lex).shape[0] == 768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indonesian-bangkok",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cos_sim(vec_1, vec_2):\n",
    "    cos_sim = CosineSimilarity(dim=0)\n",
    "    sim_vecs = cos_sim(vec_1, vec_2)\n",
    "    return float(sim_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "committed-welsh",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sent_sim(sent_1, sent_2, lex):\n",
    "    sent_vec_1 = get_sent_vec_\n",
    "    cos_sim = get_cos_sim(sent_vec_1, sent_vec_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accepted-address",
   "metadata": {},
   "source": [
    "## Type-based embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mysterious-married",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = WordEmbeddings('glove')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "particular-ensemble",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = Sentence('I can can a can.')\n",
    "embedding.embed(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "durable-enhancement",
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in sentence:\n",
    "    print(token)\n",
    "    print(token.embedding.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "least-grounds",
   "metadata": {},
   "source": [
    "## Token-based embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impressed-witch",
   "metadata": {},
   "source": [
    "### Toy example: 'bank'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "german-theme",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = [proc_sentence(sent) for sent in sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charming-basis",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_vecs = [get_sent_vec(sent, lex) for sent in sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stable-nerve",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_vecs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abroad-macedonia",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sent_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "planned-segment",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_cos_sim(sent_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alternative-balance",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    cos(vecs[0], vecs[1]),\n",
    "    cos(vecs[0], vecs[2]),\n",
    "    cos(vecs[1], vecs[2]),    \n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frozen-computer",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert cos(vecs[0], vecs[1]) > cos(vecs[0], vecs[2])\n",
    "assert cos(vecs[0], vecs[1]) > cos(vecs[1], vecs[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tropical-organ",
   "metadata": {},
   "source": [
    "### 'Cell'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polar-narrative",
   "metadata": {},
   "outputs": [],
   "source": [
    "lex = 'cell'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "featured-addition",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = [\n",
    "    'I bought a new cell phone yesterday.',\n",
    "    'Stem cell research has found a cure for cancer.'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "divided-chancellor",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = [Sentence(comm) for comm in comments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "considerable-suspension",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents_embed = embedding.embed([sent for sent in sents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surface-sandwich",
   "metadata": {},
   "outputs": [],
   "source": [
    "vecs = [tok.embedding for tok in toks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composed-anaheim",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tok in Sentence(comments[0]):\n",
    "    if tok.text == 'cell':\n",
    "        print(tok, tok.embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "persistent-moderator",
   "metadata": {},
   "source": [
    "### 'Anglo-Saxon' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wooden-dover",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.data import Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supreme-granny",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.embeddings import TransformerWordEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "involved-diana",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "critical-montreal",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = df.body[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forward-basic",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = \"This is a sentence. This is another sentence. I love Berlin.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "functional-absorption",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = SegtokSentenceSplitter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "signal-saudi",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = splitter.split(txt)\n",
    "\n",
    "print(len(sents), '\\n')\n",
    "\n",
    "for sent in sents:\n",
    "    print(len(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suspected-container",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.choices(sents, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outdoor-following",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.choices(df['body'], k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aboriginal-malpractice",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = [\n",
    "    'At the same time, as the Anglo Saxons began settling in Roman territory, they began adopting vulgar Latin words into their vocabulary.',\n",
    "    'Islamophobia here tends to refer to the racism from the WASP (white Anglo-Saxon Protestant)-types.'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annual-principal",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "rep = {\"anglo saxon\": \"anglo-saxon\", \"anglo-saxons\": \"anglo-saxon\"} \n",
    "rep = dict((re.escape(k), v) for k, v in rep.items())\n",
    "pattern = re.compile(\"|\".join(rep.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "duplicate-motor",
   "metadata": {},
   "outputs": [],
   "source": [
    "[pattern.sub(lambda m: rep[re.escape(m.group(0))], comment) for comment in comments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "asian-graph",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_sents = [splitter.split(comment) for comment in comments]\n",
    "\n",
    "print(len(comments_sents), '\\n')\n",
    "\n",
    "for comment in comments_sents:\n",
    "    print(len(comment))\n",
    "    for sent in comment:\n",
    "        print(sent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convenient-stephen",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent.replace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spoken-benchmark",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_low = [comm.lower() for comm in comments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subsequent-identifier",
   "metadata": {},
   "outputs": [],
   "source": [
    "lex = 'Anglo-Saxon'\n",
    "patterns = ['Anglo-Saxon', 'Anglo Sa']\n",
    "\n",
    "comments_tokmerge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "threatened-crazy",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = [Sentence(txt) for txt in txts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "egyptian-thermal",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents_toks = []\n",
    "for sent in sents:\n",
    "    toks = 0\n",
    "    for tok in sent:\n",
    "        if tok.text == 'Anglo-Saxon':\n",
    "            toks += 1\n",
    "    if toks >= 1:\n",
    "        print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alive-fields",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.choices(sents, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loaded-clone",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = 'Anglo-Saxon Anglo Saxon people'\n",
    "sent = Sentence(sent)\n",
    "\n",
    "for tok in sent:\n",
    "    if tok.text == 'Anglo-Saxon':\n",
    "        print(tok)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
