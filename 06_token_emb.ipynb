{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "configured-hundred",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp token_emb\n",
    "# all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "geological-billy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faced-mirror",
   "metadata": {},
   "source": [
    "# Token embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extra-isolation",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cross-dictionary",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.data import Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "curious-fraud",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.embeddings import WordEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specific-antenna",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.embeddings import TransformerWordEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "great-patio",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import CosineSimilarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exotic-absolute",
   "metadata": {},
   "source": [
    "### Load language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "realistic-grove",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = TransformerWordEmbeddings('roberta-base')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "phantom-carbon",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "viral-witness",
   "metadata": {},
   "source": [
    "### Class-less version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "devoted-simpson",
   "metadata": {},
   "outputs": [],
   "source": [
    "LEX = 'bank'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transsexual-academy",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents_strings = [\n",
    "    'He found money at the bank.', \n",
    "    'She works at a bank.', \n",
    "    \"The boat reached the river's bank.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "romantic-hepatitis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def proc_sentence(sent_string):\n",
    "    sent = Sentence(sent_string)\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naked-thriller",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_string = \"I can't do this.\"\n",
    "sent = proc_sentence(sent_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "friendly-parcel",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(sent) == 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "freelance-bolivia",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tok in sent:\n",
    "    print(tok, tok.embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "geological-thompson",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_sentence(sent, MODEL):\n",
    "    MODEL.embed(sent)\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "close-battery",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_emb = embed_sentence(sent, MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "graphic-british",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tok in sent_emb:\n",
    "    print(tok, tok.embedding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hourly-income",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(sent_emb) == 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coastal-bernard",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert sent_emb[0].embedding.shape[0] == 768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pursuant-thing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sent_toks(sent, lex):\n",
    "    sent_toks = []\n",
    "    for tok in sent:\n",
    "        if tok.text == lex:\n",
    "            sent_toks.append(tok)\n",
    "    return sent_toks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equal-niger",
   "metadata": {},
   "outputs": [],
   "source": [
    "lex = 'cell'\n",
    "sent = proc_sentence('A cell is a cell.')\n",
    "sent_emb = embed_sentence(sent, MODEL)\n",
    "sent_toks = get_sent_toks(sent_emb, lex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valued-mediterranean",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(sent_toks) == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hindu-chester",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sent_vec(sent_toks, lex):\n",
    "    sent_toks_vecs = [tok.embedding for tok in sent_toks]\n",
    "    # return vector only for the first token in the sentence, ignore the rest; alternative: take mean of all target tokens\n",
    "    sent_vec = sent_toks_vecs[0]\n",
    "    return sent_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gothic-incidence",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert get_sent_vec(sent_toks, lex).shape[0] == 768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "substantial-decline",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cos_sim(vec_1, vec_2):\n",
    "    cos_sim = CosineSimilarity(dim=0)\n",
    "    sim_vecs = cos_sim(vec_1, vec_2)\n",
    "    return float(sim_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "experienced-stake",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sent_sim(sent_1, sent_2, lex):\n",
    "    sent_vec_1 = get_sent_vec_\n",
    "    cos_sim = get_cos_sim(sent_vec_1, sent_vec_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "private-stick",
   "metadata": {},
   "source": [
    "### Class version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "younger-forty",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pressed-chrome",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastcore.basics import patch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "provincial-patch",
   "metadata": {},
   "source": [
    "#### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "signed-swift",
   "metadata": {},
   "outputs": [],
   "source": [
    "lex = 'bank'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nuclear-virtue",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents_strings = [\n",
    "    'He found money at the bank.', \n",
    "    'She works at a bank.', \n",
    "    \"The boat reached the river's bank.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "royal-testing",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_string = sents_strings[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "innovative-strengthening",
   "metadata": {},
   "source": [
    "#### Initialize `Sent` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broken-tuning",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sent():\n",
    "    def __init__(self, string, model):\n",
    "        self.string = string\n",
    "        self.model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plastic-transportation",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = Sent(sent_string, MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hydraulic-newspaper",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'He found money at the bank.'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent.string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "front-newsletter",
   "metadata": {},
   "source": [
    "#### Tokenize sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "experienced-immune",
   "metadata": {},
   "outputs": [],
   "source": [
    "@patch(as_prop=True)\n",
    "def sent(self: Sent):\n",
    "    return Sentence(self.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anticipated-suspension",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: 1 He\n",
      "Token: 2 found\n",
      "Token: 3 money\n",
      "Token: 4 at\n",
      "Token: 5 the\n",
      "Token: 6 bank\n",
      "Token: 7 .\n"
     ]
    }
   ],
   "source": [
    "for tok in sent.sent:\n",
    "    print(tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valid-attempt",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(sent.sent) == 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifty-tampa",
   "metadata": {},
   "source": [
    "#### Embed sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inner-contents",
   "metadata": {},
   "outputs": [],
   "source": [
    "@patch\n",
    "def get_sent_emb(self: Sent):\n",
    "    sent_tmp = self.sent\n",
    "    self.model.embed(sent_tmp)\n",
    "    return sent_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cosmetic-taste",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = Sent(sent_string, MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entertaining-nicholas",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_emb = sent.get_sent_emb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "perceived-acceptance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: 1 He torch.Size([768])\n",
      "Token: 2 found torch.Size([768])\n",
      "Token: 3 money torch.Size([768])\n",
      "Token: 4 at torch.Size([768])\n",
      "Token: 5 the torch.Size([768])\n",
      "Token: 6 bank torch.Size([768])\n",
      "Token: 7 . torch.Size([768])\n"
     ]
    }
   ],
   "source": [
    "for tok in sent_emb:\n",
    "    print(tok, tok.embedding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "toxic-subsection",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(sent_emb) == 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "every-underground",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert sent_emb[0].embedding.shape[0] == 768"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "communist-dutch",
   "metadata": {},
   "source": [
    "#### Get target tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vocal-working",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_toks_tgt(sent, lex):\n",
    "    sent_toks = []\n",
    "    for tok in sent:\n",
    "        if tok.text == lex:\n",
    "            sent_toks.append(tok)\n",
    "    return sent_toks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conventional-november",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_toks_tgt = get_toks_tgt(sent.sent, lex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "union-hydrogen",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(sent_toks_tgt) == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "current-gross",
   "metadata": {},
   "source": [
    "#### Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "former-heater",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Token: 6 bank]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_toks_tgt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "invisible-maintenance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'He found money at the bank.'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent.string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "warming-concern",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tok:\n",
    "    def __init__(self, Token, Sent):\n",
    "        self.text = Token.text\n",
    "        self.context = Sent.string\n",
    "        self.embedding = Token.embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unavailable-mongolia",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Sentence' object has no attribute 'sent'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-120-1666a73d8c76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mtok\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msent_emb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mtok\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTok\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtok\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtok\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtok\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtok\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Sentence' object has no attribute 'sent'"
     ]
    }
   ],
   "source": [
    "for tok in sent_emb.sent:\n",
    "    tok = Tok(tok, sent)\n",
    "    print(tok.text, tok.context, tok.embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clinical-immigration",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: 6 bank tensor([])\n"
     ]
    }
   ],
   "source": [
    "for tok in toks:\n",
    "    print(tok, tok.embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unique-subscriber",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sent_vec(sent_toks, lex):\n",
    "    sent_toks_vecs = [tok.embedding for tok in sent_toks]\n",
    "    # return vector only for the first token in the sentence, ignore the rest; alternative: take mean of all target tokens\n",
    "    sent_vec = sent_toks_vecs[0]\n",
    "    return sent_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entitled-mexico",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sent_toks' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-429d343265a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mget_sent_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent_toks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m768\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'sent_toks' is not defined"
     ]
    }
   ],
   "source": [
    "assert get_sent_vec(sent_toks, lex).shape[0] == 768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strange-sewing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cos_sim(vec_1, vec_2):\n",
    "    cos_sim = CosineSimilarity(dim=0)\n",
    "    sim_vecs = cos_sim(vec_1, vec_2)\n",
    "    return float(sim_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "centered-swaziland",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sent_sim(sent_1, sent_2, lex):\n",
    "    sent_vec_1 = get_sent_vec_\n",
    "    cos_sim = get_cos_sim(sent_vec_1, sent_vec_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "changed-proportion",
   "metadata": {},
   "source": [
    "## Type-based embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "matched-dispute",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = WordEmbeddings('glove')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detailed-excuse",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = Sentence('I can can a can.')\n",
    "embedding.embed(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "italic-season",
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in sentence:\n",
    "    print(token)\n",
    "    print(token.embedding.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satellite-drain",
   "metadata": {},
   "source": [
    "## Token-based embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protecting-subscription",
   "metadata": {},
   "source": [
    "### Toy example: 'bank'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affected-respect",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = [proc_sentence(sent) for sent in sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broadband-greene",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_vecs = [get_sent_vec(sent, lex) for sent in sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rocky-excess",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_vecs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valued-pollution",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sent_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "resistant-asthma",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_cos_sim(sent_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "other-clerk",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    cos(vecs[0], vecs[1]),\n",
    "    cos(vecs[0], vecs[2]),\n",
    "    cos(vecs[1], vecs[2]),    \n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "choice-group",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert cos(vecs[0], vecs[1]) > cos(vecs[0], vecs[2])\n",
    "assert cos(vecs[0], vecs[1]) > cos(vecs[1], vecs[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organizational-report",
   "metadata": {},
   "source": [
    "### 'Cell'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "banned-bumper",
   "metadata": {},
   "outputs": [],
   "source": [
    "lex = 'cell'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anticipated-wisdom",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = [\n",
    "    'I bought a new cell phone yesterday.',\n",
    "    'Stem cell research has found a cure for cancer.'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "particular-belize",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = [Sentence(comm) for comm in comments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "positive-humanity",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents_embed = embedding.embed([sent for sent in sents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amino-demonstration",
   "metadata": {},
   "outputs": [],
   "source": [
    "vecs = [tok.embedding for tok in toks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thermal-brooks",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tok in Sentence(comments[0]):\n",
    "    if tok.text == 'cell':\n",
    "        print(tok, tok.embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agreed-appreciation",
   "metadata": {},
   "source": [
    "### 'Anglo-Saxon' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nutritional-trout",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.data import Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "antique-placement",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.embeddings import TransformerWordEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indonesian-corner",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "resistant-radiation",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = df.body[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focal-shareware",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = \"This is a sentence. This is another sentence. I love Berlin.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polish-meaning",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = SegtokSentenceSplitter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "artificial-subscription",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = splitter.split(txt)\n",
    "\n",
    "print(len(sents), '\\n')\n",
    "\n",
    "for sent in sents:\n",
    "    print(len(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "molecular-kingston",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.choices(sents, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "third-calvin",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.choices(df['body'], k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pointed-elements",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = [\n",
    "    'At the same time, as the Anglo Saxons began settling in Roman territory, they began adopting vulgar Latin words into their vocabulary.',\n",
    "    'Islamophobia here tends to refer to the racism from the WASP (white Anglo-Saxon Protestant)-types.'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "twenty-hurricane",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "rep = {\"anglo saxon\": \"anglo-saxon\", \"anglo-saxons\": \"anglo-saxon\"} \n",
    "rep = dict((re.escape(k), v) for k, v in rep.items())\n",
    "pattern = re.compile(\"|\".join(rep.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "helpful-corner",
   "metadata": {},
   "outputs": [],
   "source": [
    "[pattern.sub(lambda m: rep[re.escape(m.group(0))], comment) for comment in comments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extraordinary-archives",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_sents = [splitter.split(comment) for comment in comments]\n",
    "\n",
    "print(len(comments_sents), '\\n')\n",
    "\n",
    "for comment in comments_sents:\n",
    "    print(len(comment))\n",
    "    for sent in comment:\n",
    "        print(sent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tutorial-memorabilia",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent.replace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprised-letters",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_low = [comm.lower() for comm in comments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "serial-vacation",
   "metadata": {},
   "outputs": [],
   "source": [
    "lex = 'Anglo-Saxon'\n",
    "patterns = ['Anglo-Saxon', 'Anglo Sa']\n",
    "\n",
    "comments_tokmerge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "superb-softball",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = [Sentence(txt) for txt in txts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scenic-piano",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents_toks = []\n",
    "for sent in sents:\n",
    "    toks = 0\n",
    "    for tok in sent:\n",
    "        if tok.text == 'Anglo-Saxon':\n",
    "            toks += 1\n",
    "    if toks >= 1:\n",
    "        print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expensive-trout",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.choices(sents, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "normal-visit",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = 'Anglo-Saxon Anglo Saxon people'\n",
    "sent = Sentence(sent)\n",
    "\n",
    "for tok in sent:\n",
    "    if tok.text == 'Anglo-Saxon':\n",
    "        print(tok)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
